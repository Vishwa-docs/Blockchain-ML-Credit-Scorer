{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a6fba2",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8812aff",
   "metadata": {},
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c9d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b015e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45230221",
   "metadata": {},
   "source": [
    "# Load and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb8122a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Task Files/compoundV2_transactions_ethereum_chunk_0.json...\n",
      "Loading Task Files/compoundV2_transactions_ethereum_chunk_1.json...\n",
      "Loading Task Files/compoundV2_transactions_ethereum_chunk_2.json...\n",
      "deposits: 30000 transactions\n",
      "borrows: 30000 transactions\n",
      "repays: 30000 transactions\n",
      "withdraws: 30000 transactions\n",
      "liquidations: 0 transactions\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_paths):\n",
    "    \"\"\"Load and parse the JSON transaction data from multiple files.\"\"\"\n",
    "    all_data = {\n",
    "        'deposits': [],\n",
    "        'borrows': [],\n",
    "        'repays': [],\n",
    "        'withdraws': [],\n",
    "        'liquidations': []\n",
    "    }\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        print(f\"Loading {file_path}...\")\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        for transaction_type in all_data.keys():\n",
    "            if transaction_type in data:\n",
    "                all_data[transaction_type].extend(data[transaction_type])\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "file_paths = [\n",
    "    'Task Files/compoundV2_transactions_ethereum_chunk_0.json',\n",
    "    'Task Files/compoundV2_transactions_ethereum_chunk_1.json',\n",
    "    'Task Files/compoundV2_transactions_ethereum_chunk_2.json'\n",
    "]\n",
    "\n",
    "# Load Data\n",
    "transaction_data = load_data(file_paths)\n",
    "\n",
    "# Print transaction counts\n",
    "for tx_type, transactions in transaction_data.items():\n",
    "    print(f\"{tx_type}: {len(transactions)} transactions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee995932",
   "metadata": {},
   "source": [
    "## Convert into Structed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86308d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transaction_df(transactions, tx_type):\n",
    "    \"\"\"Convert transaction list to a DataFrame with consistent structure.\"\"\"\n",
    "    df_rows = []\n",
    "    \n",
    "    for tx in transactions:\n",
    "        row = {\n",
    "            'wallet_id': tx['account']['id'],\n",
    "            'timestamp': int(tx['timestamp']),\n",
    "            'datetime': datetime.fromtimestamp(int(tx['timestamp'])),\n",
    "            'amount': float(tx['amount']),\n",
    "            'amountUSD': float(tx['amountUSD']) if 'amountUSD' in tx else 0,\n",
    "            'asset_id': tx['asset']['id'],\n",
    "            'asset_symbol': tx['asset']['symbol'],\n",
    "            'hash': tx['hash'],\n",
    "            'tx_id': tx['id'],\n",
    "            'tx_type': tx_type\n",
    "        }\n",
    "        \n",
    "        # Add liquidation-specific fields\n",
    "        if tx_type == 'liquidations':\n",
    "            row['liquidator'] = tx.get('liquidator', {}).get('id', '')\n",
    "            row['liquidatee'] = tx.get('liquidatee', {}).get('id', '')\n",
    "        else:\n",
    "            # For non-liquidation transactions, set these fields to empty strings\n",
    "            row['liquidator'] = ''\n",
    "            row['liquidatee'] = ''\n",
    "            \n",
    "        df_rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9223a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deposits DataFrame shape: (30000, 12)\n",
      "borrows DataFrame shape: (30000, 12)\n",
      "repays DataFrame shape: (30000, 12)\n",
      "withdraws DataFrame shape: (30000, 12)\n",
      "liquidations DataFrame shape: (0, 0)\n",
      "Combined DataFrame shape: (120000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames for each transaction type\n",
    "dfs = {}\n",
    "for tx_type, transactions in transaction_data.items():\n",
    "    dfs[tx_type] = create_transaction_df(transactions, tx_type)\n",
    "    print(f\"{tx_type} DataFrame shape: {dfs[tx_type].shape}\")\n",
    "\n",
    "# Combine all transactions into a single DataFrame\n",
    "all_transactions = pd.concat(dfs.values(), ignore_index=True)\n",
    "print(f\"Combined DataFrame shape: {all_transactions.shape}\")\n",
    "\n",
    "# Sort by timestamp\n",
    "all_transactions = all_transactions.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4354735",
   "metadata": {},
   "source": [
    "## Data Exploration (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aadfb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transaction types:\n",
      "tx_type\n",
      "deposits     30000\n",
      "borrows      30000\n",
      "withdraws    30000\n",
      "repays       30000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Asset types:\n",
      "asset_symbol\n",
      "DAI     62721\n",
      "ETH     23934\n",
      "USDC    22331\n",
      "BAT      3601\n",
      "ZRX      2829\n",
      "REP      2414\n",
      "WBTC     2170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Time range:\n",
      "Start: 2019-05-07 07:11:22\n",
      "End: 2020-04-15 06:24:24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTransaction types:\")\n",
    "print(all_transactions['tx_type'].value_counts())\n",
    "\n",
    "print(\"\\nAsset types:\")\n",
    "print(all_transactions['asset_symbol'].value_counts())\n",
    "\n",
    "print(\"\\nTime range:\")\n",
    "print(f\"Start: {all_transactions['datetime'].min()}\")\n",
    "print(f\"End: {all_transactions['datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562c977",
   "metadata": {},
   "source": [
    "# Feature Engineering (For each Wallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c1672e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_wallet_features(transactions_df):\n",
    "    \"\"\"Extract wallet-level features from transaction data.\"\"\"\n",
    "    # Sort by timestamp\n",
    "    wallet_groups = transactions_df.groupby('wallet_id')\n",
    "    wallet_features = []\n",
    "    \n",
    "    for wallet_id, wallet_txs in wallet_groups:\n",
    "        # Skip wallets with very few transactions (likely noise)\n",
    "        if len(wallet_txs) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Group transactions by type\n",
    "        deposits = wallet_txs[wallet_txs['tx_type'] == 'deposits']\n",
    "        borrows = wallet_txs[wallet_txs['tx_type'] == 'borrows']\n",
    "        repays = wallet_txs[wallet_txs['tx_type'] == 'repays']\n",
    "        withdraws = wallet_txs[wallet_txs['tx_type'] == 'withdraws']\n",
    "        \n",
    "        # For liquidations, we need to check both as liquidator and liquidatee\n",
    "        liquidations = wallet_txs[wallet_txs['tx_type'] == 'liquidations']\n",
    "        liquidations_as_liquidatee = liquidations[liquidations['liquidatee'] == wallet_id]\n",
    "        liquidations_as_liquidator = liquidations[liquidations['liquidator'] == wallet_id]\n",
    "        \n",
    "        # Time-based features\n",
    "        first_tx_time = wallet_txs['timestamp'].min()\n",
    "        last_tx_time = wallet_txs['timestamp'].max()\n",
    "        account_age_days = (last_tx_time - first_tx_time) / (60 * 60 * 24)\n",
    "        \n",
    "        # Transaction frequency\n",
    "        if account_age_days > 0:\n",
    "            tx_frequency = len(wallet_txs) / account_age_days\n",
    "        else:\n",
    "            tx_frequency = 0\n",
    "            \n",
    "        # Volume metrics\n",
    "        total_deposit_usd = deposits['amountUSD'].sum()\n",
    "        total_borrow_usd = borrows['amountUSD'].sum()\n",
    "        total_repay_usd = repays['amountUSD'].sum()\n",
    "        total_withdraw_usd = withdraws['amountUSD'].sum()\n",
    "        total_liquidated_usd = liquidations_as_liquidatee['amountUSD'].sum()\n",
    "        \n",
    "        # Repayment behavior\n",
    "        if total_borrow_usd > 0:\n",
    "            repay_ratio = total_repay_usd / total_borrow_usd\n",
    "        else:\n",
    "            repay_ratio = 0\n",
    "            \n",
    "        # Liquidation risk\n",
    "        if total_borrow_usd > 0:\n",
    "            liquidation_ratio = total_liquidated_usd / total_borrow_usd\n",
    "        else:\n",
    "            liquidation_ratio = 0\n",
    "            \n",
    "        # Asset diversity\n",
    "        unique_assets = wallet_txs['asset_symbol'].nunique()\n",
    "        \n",
    "        # Transaction patterns\n",
    "        borrow_deposit_ratio = total_borrow_usd / (total_deposit_usd + 1)  # Add 1 to avoid division by zero\n",
    "        withdraw_deposit_ratio = total_withdraw_usd / (total_deposit_usd + 1)\n",
    "        \n",
    "        # Time between transactions\n",
    "        if len(wallet_txs) > 1:\n",
    "            wallet_txs_sorted = wallet_txs.sort_values('timestamp')\n",
    "            time_diffs = wallet_txs_sorted['timestamp'].diff().dropna()\n",
    "            avg_time_between_txs = time_diffs.mean() / (60 * 60)  # in hours\n",
    "            std_time_between_txs = time_diffs.std() / (60 * 60) if len(time_diffs) > 1 else 0\n",
    "            \n",
    "            # Volatility in transaction timing\n",
    "            time_cv = std_time_between_txs / (avg_time_between_txs + 1)\n",
    "            \n",
    "            # Volatility in transaction amounts\n",
    "            amount_volatility = wallet_txs['amountUSD'].std() / (wallet_txs['amountUSD'].mean() + 1)\n",
    "        else:\n",
    "            avg_time_between_txs = 0\n",
    "            std_time_between_txs = 0\n",
    "            time_cv = 0\n",
    "            amount_volatility = 0\n",
    "            \n",
    "        # Check for liquidator behavior\n",
    "        is_liquidator = len(liquidations_as_liquidator) > 0\n",
    "        \n",
    "        # Borrowing efficiency\n",
    "        if len(borrows) > 0:\n",
    "            repay_to_borrow_ratio = len(repays) / len(borrows)\n",
    "        else:\n",
    "            repay_to_borrow_ratio = 0\n",
    "            \n",
    "        # Recency feature\n",
    "        current_time = datetime.now().timestamp()\n",
    "        days_since_last_tx = (current_time - last_tx_time) / (60 * 60 * 24)\n",
    "        \n",
    "        # Collect features\n",
    "        features = {\n",
    "            'wallet_id': wallet_id,\n",
    "            'tx_count': len(wallet_txs),\n",
    "            'deposit_count': len(deposits),\n",
    "            'borrow_count': len(borrows),\n",
    "            'repay_count': len(repays),\n",
    "            'withdraw_count': len(withdraws),\n",
    "            'liquidated_count': len(liquidations_as_liquidatee),\n",
    "            'liquidator_count': len(liquidations_as_liquidator),\n",
    "            'is_liquidator': is_liquidator,\n",
    "            'account_age_days': account_age_days,\n",
    "            'tx_frequency': tx_frequency,\n",
    "            'total_deposit_usd': total_deposit_usd,\n",
    "            'total_borrow_usd': total_borrow_usd,\n",
    "            'total_repay_usd': total_repay_usd,\n",
    "            'total_withdraw_usd': total_withdraw_usd,\n",
    "            'total_liquidated_usd': total_liquidated_usd,\n",
    "            'repay_ratio': repay_ratio,\n",
    "            'liquidation_ratio': liquidation_ratio,\n",
    "            'unique_assets': unique_assets,\n",
    "            'borrow_deposit_ratio': borrow_deposit_ratio,\n",
    "            'withdraw_deposit_ratio': withdraw_deposit_ratio,\n",
    "            'avg_time_between_txs': avg_time_between_txs,\n",
    "            'std_time_between_txs': std_time_between_txs,\n",
    "            'first_tx_time': first_tx_time,\n",
    "            'last_tx_time': last_tx_time,\n",
    "            'time_consistency': time_cv,\n",
    "            'amount_volatility': amount_volatility,\n",
    "            'repay_to_borrow_ratio': repay_to_borrow_ratio,\n",
    "            'days_since_last_tx': days_since_last_tx\n",
    "        }\n",
    "        \n",
    "        # Add asset-specific metrics\n",
    "        asset_counts = wallet_txs['asset_symbol'].value_counts()\n",
    "        for asset, count in asset_counts.items():\n",
    "            features[f'asset_{asset}_count'] = count\n",
    "            \n",
    "        # Add transaction type percentages\n",
    "        for tx_type in ['deposits', 'borrows', 'repays', 'withdraws', 'liquidations']:\n",
    "            features[f'{tx_type}_pct'] = len(wallet_txs[wallet_txs['tx_type'] == tx_type]) / len(wallet_txs)\n",
    "            \n",
    "        wallet_features.append(features)\n",
    "        \n",
    "    return pd.DataFrame(wallet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5886622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated features for 6607 wallets\n",
      "Feature columns: ['wallet_id', 'tx_count', 'deposit_count', 'borrow_count', 'repay_count', 'withdraw_count', 'liquidated_count', 'liquidator_count', 'is_liquidator', 'account_age_days', 'tx_frequency', 'total_deposit_usd', 'total_borrow_usd', 'total_repay_usd', 'total_withdraw_usd', 'total_liquidated_usd', 'repay_ratio', 'liquidation_ratio', 'unique_assets', 'borrow_deposit_ratio', 'withdraw_deposit_ratio', 'avg_time_between_txs', 'std_time_between_txs', 'first_tx_time', 'last_tx_time', 'time_consistency', 'amount_volatility', 'repay_to_borrow_ratio', 'days_since_last_tx', 'asset_DAI_count', 'asset_ETH_count', 'asset_USDC_count', 'asset_BAT_count', 'asset_ZRX_count', 'asset_WBTC_count', 'deposits_pct', 'borrows_pct', 'repays_pct', 'withdraws_pct', 'liquidations_pct', 'asset_REP_count']\n",
      "Wallet features saved to wallet_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate wallet features\n",
    "wallet_features_df = engineer_wallet_features(all_transactions)\n",
    "print(f\"Generated features for {len(wallet_features_df)} wallets\")\n",
    "print(f\"Feature columns: {wallet_features_df.columns.tolist()}\")\n",
    "\n",
    "# Save the features\n",
    "wallet_features_df.to_csv(\"Deliverables/wallet_features.csv\", index=False)\n",
    "print(\"Wallet features saved to wallet_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ef719",
   "metadata": {},
   "source": [
    "# Detect Anomalied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39b7ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(df, contamination=0.05):\n",
    "    \"\"\"Detect anomalous wallets using Isolation Forest.\"\"\"\n",
    "    \n",
    "    anomaly_features = [\n",
    "        'tx_count', 'deposit_count', 'borrow_count', 'repay_count', \n",
    "        'withdraw_count', 'liquidated_count', 'tx_frequency',\n",
    "        'total_deposit_usd', 'total_borrow_usd', 'total_repay_usd', \n",
    "        'total_withdraw_usd', 'repay_ratio', 'borrow_deposit_ratio',\n",
    "        'withdraw_deposit_ratio', 'avg_time_between_txs', 'amount_volatility'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all features exist\n",
    "    anomaly_features = [f for f in anomaly_features if f in df.columns]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df[anomaly_features])\n",
    "    \n",
    "    # Apply Isolation Forest for anomaly detection\n",
    "    isoforest = IsolationForest(contamination=contamination, random_state=42, n_estimators=100)\n",
    "    df['anomaly_score'] = isoforest.fit_predict(scaled_features)\n",
    "    \n",
    "    # Add anomaly probability score (higher means more anomalous)\n",
    "    df['anomaly_probability'] = -isoforest.score_samples(scaled_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2597467",
   "metadata": {},
   "source": [
    "# Credit Scoring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8afe096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_credit_scoring_model(wallet_features):\n",
    "    \"\"\"Create a credit scoring model based on wallet features.\"\"\"\n",
    "\n",
    "    df = wallet_features.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Detect anomalies\n",
    "    df = detect_anomalies(df)\n",
    "    \n",
    "    # 1. Repayment behavior (30% of score)\n",
    "    repayment_score = 30 * np.where(df['repay_ratio'] > 0.95, 1, \n",
    "                     np.where(df['repay_ratio'] > 0.8, 0.8,\n",
    "                     np.where(df['repay_ratio'] > 0.6, 0.6,\n",
    "                     np.where(df['repay_ratio'] > 0.4, 0.4,\n",
    "                     np.where(df['repay_ratio'] > 0.2, 0.2, 0)))))\n",
    "    \n",
    "    # 2. Liquidation risk (25% of score)\n",
    "    liquidation_score = 25 * (1 - np.clip(df['liquidation_ratio'] * 5, 0, 1))\n",
    "    \n",
    "    # 3. Account stability (15% of score)\n",
    "    stability_score = 15 * np.where(df['account_age_days'] > 180, 1,\n",
    "                      np.where(df['account_age_days'] > 90, 0.8,\n",
    "                      np.where(df['account_age_days'] > 30, 0.6,\n",
    "                      np.where(df['account_age_days'] > 7, 0.4, 0.2))))\n",
    "    \n",
    "    # 4. Transaction patterns (15% of score)\n",
    "    # Identify potential bots or exploitative behavior\n",
    "    df['potential_bot'] = (df['tx_frequency'] > df['tx_frequency'].quantile(0.95)) & \\\n",
    "                          (df['std_time_between_txs'] < df['std_time_between_txs'].quantile(0.10))\n",
    "    \n",
    "    # Identify high-risk behavior\n",
    "    df['high_borrow_risk'] = df['borrow_deposit_ratio'] > df['borrow_deposit_ratio'].quantile(0.75)\n",
    "    df['high_withdraw_risk'] = df['withdraw_deposit_ratio'] > df['withdraw_deposit_ratio'].quantile(0.75)\n",
    "    \n",
    "    tx_pattern_score = 15 * (1 - \n",
    "                           np.where(df['potential_bot'] == True, 0.8, 0) -\n",
    "                           np.where(df['high_borrow_risk'] == True, 0.4, 0) -\n",
    "                           np.where(df['high_withdraw_risk'] == True, 0.2, 0))\n",
    "    \n",
    "    # 5. Asset diversity (15% of score)\n",
    "    diversity_score = 15 * np.where(df['unique_assets'] > 4, 1,\n",
    "                      np.where(df['unique_assets'] > 2, 0.7,\n",
    "                      np.where(df['unique_assets'] > 1, 0.4, 0.2)))\n",
    "    \n",
    "    # Combine all components\n",
    "    df['credit_score'] = (repayment_score + liquidation_score + stability_score + \n",
    "                          tx_pattern_score + diversity_score)\n",
    "    \n",
    "    # Apply anomaly detection penalty\n",
    "    df.loc[df['anomaly_score'] == -1, 'credit_score'] *= 0.5\n",
    "    \n",
    "    # Ensure score is between 0 and 100\n",
    "    df['credit_score'] = df['credit_score'].clip(0, 100).round().astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c1eae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_scores = create_credit_scoring_model(wallet_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18262f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full results\n",
    "wallet_scores.to_csv(\"Deliverables/all_wallet_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10245b19",
   "metadata": {},
   "source": [
    "# Visualization and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa468ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(wallet_scores):\n",
    "    \"\"\"Generate visualizations for the credit scoring analysis.\"\"\"\n",
    "    # Score distribution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Main plot - overall distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.histplot(wallet_scores['credit_score'], bins=20, kde=True)\n",
    "    plt.title('Distribution of Wallet Credit Scores')\n",
    "    plt.xlabel('Credit Score')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Feature importance visualization\n",
    "    plt.subplot(2, 2, 2)\n",
    "    feature_importance = {\n",
    "        'Repayment Behavior': 30,\n",
    "        'Liquidation Risk': 25,\n",
    "        'Account Stability': 15,\n",
    "        'Transaction Patterns': 15,\n",
    "        'Asset Diversity': 15\n",
    "    }\n",
    "    plt.pie(feature_importance.values(), labels=feature_importance.keys(), autopct='%1.1f%%')\n",
    "    plt.title('Credit Score Component Weights')\n",
    "    \n",
    "    # Score by transaction count\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.scatterplot(data=wallet_scores, x='tx_count', y='credit_score', alpha=0.5)\n",
    "    plt.title('Credit Score vs Transaction Count')\n",
    "    plt.xlabel('Number of Transactions')\n",
    "    plt.ylabel('Credit Score')\n",
    "    \n",
    "    # Score by account age\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.scatterplot(data=wallet_scores, x='account_age_days', y='credit_score', alpha=0.5)\n",
    "    plt.title('Credit Score vs Account Age')\n",
    "    plt.xlabel('Account Age (days)')\n",
    "    plt.ylabel('Credit Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Deliverables/score_analysis.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b91028df",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_visualizations(wallet_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926fc011",
   "metadata": {},
   "source": [
    "# Analysis of Highest and Lowest Scoring Wallets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "264391c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Highest and Lowest Scoring Wallets\n",
    "def get_wallet_strengths(wallet):\n",
    "    \"\"\"Identify key strengths of a high-scoring wallet.\"\"\"\n",
    "    strengths = []\n",
    "    \n",
    "    # Check for healthy repayment behavior\n",
    "    if wallet['repay_ratio'] > 0.95:\n",
    "        strengths.append(\"Excellent repayment behavior\")\n",
    "        \n",
    "    # Check for no liquidations\n",
    "    if wallet['liquidated_count'] == 0:\n",
    "        strengths.append(\"No liquidation history\")\n",
    "        \n",
    "    # Check for active user\n",
    "    if wallet['tx_count'] > 10:\n",
    "        strengths.append(\"Active and consistent protocol usage\")\n",
    "        \n",
    "    # Check for diversified assets\n",
    "    if wallet['unique_assets'] > 3:\n",
    "        strengths.append(\"Diversified asset portfolio\")\n",
    "        \n",
    "    # Check for long-term participation\n",
    "    if wallet['account_age_days'] > 90:\n",
    "        strengths.append(\"Long-term protocol participant\")\n",
    "        \n",
    "    # Check for normal transaction patterns\n",
    "    if wallet['anomaly_score'] == 1:\n",
    "        strengths.append(\"Normal transaction patterns\")\n",
    "        \n",
    "    return strengths\n",
    "\n",
    "def get_wallet_weaknesses(wallet):\n",
    "    \"\"\"Identify key weaknesses of a low-scoring wallet.\"\"\"\n",
    "    weaknesses = []\n",
    "    \n",
    "    # Check for poor repayment behavior\n",
    "    if wallet['repay_ratio'] < 0.5:\n",
    "        weaknesses.append(\"Poor repayment behavior\")\n",
    "        \n",
    "    # Check for liquidations\n",
    "    if wallet['liquidated_count'] > 0:\n",
    "        weaknesses.append(f\"Has been liquidated {wallet['liquidated_count']} times\")\n",
    "        \n",
    "    # Check for bot-like behavior\n",
    "    if wallet.get('potential_bot', False):\n",
    "        weaknesses.append(\"Shows bot-like transaction patterns\")\n",
    "        \n",
    "    # Check for high borrowing risk\n",
    "    if wallet.get('high_borrow_risk', False):\n",
    "        weaknesses.append(\"High borrowing relative to deposits\")\n",
    "        \n",
    "    # Check for high withdrawal risk\n",
    "    if wallet.get('high_withdraw_risk', False):\n",
    "        weaknesses.append(\"Excessive withdrawals relative to deposits\")\n",
    "        \n",
    "    # Check for liquidator behavior\n",
    "    if wallet['is_liquidator']:\n",
    "        weaknesses.append(\"Acts as a liquidator (potentially predatory)\")\n",
    "        \n",
    "    # Check for anomalous behavior\n",
    "    if wallet['anomaly_score'] == -1:\n",
    "        weaknesses.append(\"Exhibits anomalous transaction patterns\")\n",
    "        \n",
    "    return weaknesses\n",
    "\n",
    "def analyze_wallet_examples(wallet_scores, all_transactions, n=5):\n",
    "    \"\"\"Analyze examples of high and low scoring wallets.\"\"\"\n",
    "    # Get top and bottom n wallets\n",
    "    top_wallets = wallet_scores.sort_values('credit_score', ascending=False).head(n)\n",
    "    bottom_wallets = wallet_scores.sort_values('credit_score').head(n)\n",
    "    \n",
    "    analysis = {'high_scoring_wallets': [], 'low_scoring_wallets': []}\n",
    "    \n",
    "    # Analyze high scoring wallets\n",
    "    for _, wallet in top_wallets.iterrows():\n",
    "        wallet_id = wallet['wallet_id']\n",
    "        wallet_txs = all_transactions[all_transactions['wallet_id'] == wallet_id]\n",
    "        \n",
    "        # Calculate additional metrics for analysis\n",
    "        asset_distribution = wallet_txs['asset_symbol'].value_counts(normalize=True).to_dict()\n",
    "        avg_tx_size = wallet_txs['amountUSD'].mean()\n",
    "        max_tx_size = wallet_txs['amountUSD'].max()\n",
    "        \n",
    "        # Time-based patterns\n",
    "        wallet_txs_sorted = wallet_txs.sort_values('timestamp')\n",
    "        tx_times = pd.to_datetime(wallet_txs_sorted['timestamp'], unit='s')\n",
    "        hour_distribution = tx_times.dt.hour.value_counts(normalize=True).to_dict()\n",
    "        weekday_distribution = tx_times.dt.dayofweek.value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        analysis['high_scoring_wallets'].append({\n",
    "            'wallet_id': wallet_id,\n",
    "            'credit_score': wallet['credit_score'],\n",
    "            'transaction_count': len(wallet_txs),\n",
    "            'unique_assets': wallet_txs['asset_symbol'].nunique(),\n",
    "            'transaction_types': wallet_txs['tx_type'].value_counts().to_dict(),\n",
    "            'total_volume_usd': wallet_txs['amountUSD'].sum(),\n",
    "            'repay_ratio': wallet['repay_ratio'],\n",
    "            'liquidation_ratio': wallet['liquidation_ratio'],\n",
    "            'account_age_days': wallet['account_age_days'],\n",
    "            'is_liquidator': wallet['is_liquidator'],\n",
    "            'key_strengths': get_wallet_strengths(wallet),\n",
    "            'asset_distribution': asset_distribution,\n",
    "            'avg_tx_size': avg_tx_size,\n",
    "            'max_tx_size': max_tx_size,\n",
    "            'hour_distribution': hour_distribution,\n",
    "            'weekday_distribution': weekday_distribution\n",
    "        })\n",
    "    \n",
    "    # Analyze low scoring wallets\n",
    "    for _, wallet in bottom_wallets.iterrows():\n",
    "        wallet_id = wallet['wallet_id']\n",
    "        wallet_txs = all_transactions[all_transactions['wallet_id'] == wallet_id]\n",
    "        \n",
    "        # Calculate additional metrics for analysis\n",
    "        asset_distribution = wallet_txs['asset_symbol'].value_counts(normalize=True).to_dict()\n",
    "        avg_tx_size = wallet_txs['amountUSD'].mean()\n",
    "        max_tx_size = wallet_txs['amountUSD'].max()\n",
    "        \n",
    "        # Time-based patterns\n",
    "        wallet_txs_sorted = wallet_txs.sort_values('timestamp')\n",
    "        tx_times = pd.to_datetime(wallet_txs_sorted['timestamp'], unit='s')\n",
    "        hour_distribution = tx_times.dt.hour.value_counts(normalize=True).to_dict()\n",
    "        weekday_distribution = tx_times.dt.dayofweek.value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        analysis['low_scoring_wallets'].append({\n",
    "            'wallet_id': wallet_id,\n",
    "            'credit_score': wallet['credit_score'],\n",
    "            'transaction_count': len(wallet_txs),\n",
    "            'unique_assets': wallet_txs['asset_symbol'].nunique(),\n",
    "            'transaction_types': wallet_txs['tx_type'].value_counts().to_dict(),\n",
    "            'total_volume_usd': wallet_txs['amountUSD'].sum(),\n",
    "            'repay_ratio': wallet['repay_ratio'],\n",
    "            'liquidation_ratio': wallet['liquidation_ratio'],\n",
    "            'account_age_days': wallet['account_age_days'],\n",
    "            'is_liquidator': wallet['is_liquidator'],\n",
    "            'key_weaknesses': get_wallet_weaknesses(wallet),\n",
    "            'asset_distribution': asset_distribution,\n",
    "            'avg_tx_size': avg_tx_size,\n",
    "            'max_tx_size': max_tx_size,\n",
    "            'hour_distribution': hour_distribution,\n",
    "            'weekday_distribution': weekday_distribution\n",
    "        })\n",
    "    \n",
    "    with open('Deliverables/wallet_analysis.json', 'w') as f:\n",
    "        json.dump(analysis, f, indent=2)\n",
    "        \n",
    "    # Print a summary of the analysis\n",
    "    print(\"\\nScoring Wallet Examples:\")\n",
    "    for wallet in analysis['high_scoring_wallets']:\n",
    "        print(f\"Wallet {wallet['wallet_id'][:10]}... Score: {wallet['credit_score']}\")\n",
    "        print(f\"Strengths: {', '.join(wallet['key_strengths'])}\")\n",
    "        \n",
    "    print(\"\\nScoring Wallet Examples:\")\n",
    "    for wallet in analysis['low_scoring_wallets']:\n",
    "        print(f\"Wallet {wallet['wallet_id'][:10]}... Score: {wallet['credit_score']}\")\n",
    "        print(f\"Weaknesses: {', '.join(wallet['key_weaknesses'])}\")\n",
    "        \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d54e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring Wallet Examples:\n",
      "Wallet 0x003c52a7... Score: 100\n",
      "Strengths: Excellent repayment behavior, No liquidation history, Active and consistent protocol usage, Diversified asset portfolio, Long-term protocol participant, Normal transaction patterns\n",
      "Wallet 0xd19604ef... Score: 100\n",
      "Strengths: Excellent repayment behavior, No liquidation history, Active and consistent protocol usage, Diversified asset portfolio, Long-term protocol participant, Normal transaction patterns\n",
      "Wallet 0x869a032b... Score: 100\n",
      "Strengths: Excellent repayment behavior, No liquidation history, Active and consistent protocol usage, Diversified asset portfolio, Long-term protocol participant, Normal transaction patterns\n",
      "Wallet 0xc95be285... Score: 100\n",
      "Strengths: Excellent repayment behavior, No liquidation history, Diversified asset portfolio, Long-term protocol participant, Normal transaction patterns\n",
      "Wallet 0x5445f987... Score: 100\n",
      "Strengths: Excellent repayment behavior, No liquidation history, Active and consistent protocol usage, Diversified asset portfolio, Long-term protocol participant, Normal transaction patterns\n",
      "\n",
      "Scoring Wallet Examples:\n",
      "Wallet 0xa592cb9b... Score: 17\n",
      "Weaknesses: Poor repayment behavior, Shows bot-like transaction patterns, Exhibits anomalous transaction patterns\n",
      "Wallet 0xc17c8806... Score: 22\n",
      "Weaknesses: Poor repayment behavior, High borrowing relative to deposits, Exhibits anomalous transaction patterns\n",
      "Wallet 0x04b35d8e... Score: 22\n",
      "Weaknesses: Poor repayment behavior, High borrowing relative to deposits, Exhibits anomalous transaction patterns\n",
      "Wallet 0xab72a886... Score: 23\n",
      "Weaknesses: Poor repayment behavior, Excessive withdrawals relative to deposits, Exhibits anomalous transaction patterns\n",
      "Wallet 0xcb84f5ca... Score: 23\n",
      "Weaknesses: Poor repayment behavior, Excessive withdrawals relative to deposits, Exhibits anomalous transaction patterns\n"
     ]
    }
   ],
   "source": [
    "wallet_analysis = analyze_wallet_examples(wallet_scores, all_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1a27dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1000 wallets saved to top1000wallets.csv\n"
     ]
    }
   ],
   "source": [
    "# Save top 1000 wallets to CSV\n",
    "top_1000_wallets = wallet_scores.sort_values('credit_score', ascending=False).head(1000)\n",
    "top_1000_wallets[['wallet_id', 'credit_score']].to_csv(\"Deliverables/top1000wallets.csv\", index=False)\n",
    "print(\"Top 1000 wallets saved to top1000wallets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
